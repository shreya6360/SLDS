# -*- coding: utf-8 -*-
"""generate_test_hist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cn8lYKf-tMn_fvtTjCHKyc993s6Q6UHu
"""

# Importing the required libraries

import numpy as np
import cv2
import os
import pickle
from sklearn.cluster import MiniBatchKMeans

n_classes = 36
clustering_factor = 6

def surf_features(images):
    surf_vectors_list = {}
    surf_descriptors_list = []
    surf = cv2.xfeatures2d.SURF_create()
    for key, value in images.items():
        print(key, "Started")
        features = []
        for img in value:
            kp, desc = surf.detectAndCompute(img, None)
            if desc is not None:
                surf_descriptors_list.extend(desc)
                features.append(desc)
        surf_vectors_list[key] = features
        print(key, " Completed!")
    return [surf_descriptors_list, surf_vectors_list]

def train_kmeans(descriptors, k):
    kmeans = MiniBatchKMeans(n_clusters=k, random_state=42)
    kmeans.fit(descriptors)
    visual_words = kmeans.cluster_centers_
    return visual_words, kmeans

# Loading train images into dictionaries which holds all images category by category

def load_images_by_category(folder):
    images = {}
    for label in os.listdir(folder):
        print(label, " started")
        category = []
        path = folder+'/'+label
        for image in os.listdir(path):
            img = cv2.imread(path+'/'+image)
            new_img = cv2.resize(img, (128, 128))
            if new_img is not None:
                category.append(new_img)
        images[label] = category
        print(label, "ended")
    return images

# Creating histograms for train images

def create_histogram(all_bows, kmeans):
    features_dict = {}
    for key, value in all_bows.items():
        print(key, " Started!")
        category = []
        for desc in value:
            visual_words = kmeans.predict(desc)
            hist = np.array(np.bincount(visual_words, minlength=n_classes*clustering_factor))
            category.append(hist)
        features_dict[key] = category
        print(key, " Completed!")
    return features_dict

train_folder = 'Code/Preprocessing/ISLDatasets/Train-Test/Train'
test_folder = 'Code/Preprocessing/ISLDatasets/Train-Test/Test'

# Load train images
train_images = load_images_by_category(train_folder)

# Extracting SURF features from each image stored in train_images list
surfs = surf_features(train_images)
all_train_descriptors = surfs[0]
train_descriptors_by_class = surfs[1]

# Train the KMeans model
visual_words, kmeans = train_kmeans(all_train_descriptors, n_classes * clustering_factor)

# Save the trained KMeans model for later use
with open('/content/drive/MyDrive/SavedFiles/kmeans_model_surf.pkl', 'wb') as kmeans_file:
    pickle.dump(kmeans, kmeans_file)

# Load test images
test_images = load_images_by_category(test_folder)

# Load the trained KMeans model for testing
with open('/content/drive/MyDrive/SavedFiles/kmeans_model_surf.pkl', 'rb') as kmeans_file:
    kmeans = pickle.load(kmeans_file)

# Extract SURF features from the test images
surf_test = surf_features(test_images)[1]

# Create histograms from extracted SURF features
bows_test = create_histogram(surf_test, kmeans)

import csv
loc = 'Code/Classification/csvfiles/test.csv'
with open(loc, 'w', newline='') as file:
    writer = csv.writer(file)
    header = []
    for i in range(1, n_classes * clustering_factor + 1):
        header.append(str('pixel') + str(i))
    header.append('Label')
    writer.writerow(header)
    count = 0
    for label in bows_test:
        # print(len(bows_test[label]))
        for i in range(len(bows_test[label])):
            lst = []
            for j in range(150):
                lst.append(bows_test[label][i][j])
            lst.append(label)
            writer.writerow(lst)
